# IMPALA

IMPALA - 1 GPU 200 workers
Batched A2C - Single Machine - 32 workers
A3C - Single Machine - 32 workers
A3C - Distributed - 200 workers

IMPALA greatly outperforms distributed A3C
~ 10x more data efficient and 2x overall final performance.

Positive transfer from multi-task training with IMPALA.

# SPIRAL

### Explaining environments / generating samples
- Deep learning -> implicit
- Using tools
- Writing programs

### Use a painting tool to draw images
- Learn the control space


