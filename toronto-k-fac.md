#K-FACTOR 근사를 활용한 분산 Second-order 최적화

###DISTRIBUTED SECOND-ORDER OPTIMIZATION USING KRONECKER-FACTORED APPROXIMATIONS

```
Jimmy BaUniversity of Torontojimmy@psi.toronto.eduRoger GrosseUniversity of Torontorgrosse@cs.toronto.eduJames MartensUniversity of Torontoand Google DeepMind jmartens@cs.toronto.edu
```

# ABSTRACT

더 많은 컴퓨터 자원이 사용 가능 해지면 기계 학습 연구자는 확률 적 하강 (SGD)을 사용하여 수백만 개의 데이터 포인트에서 더 큰 신경 네트워크를 훈련시킵니다. SGD는 데이터 세트의 크기와 모델의 매개 변수 개수면에서 잘 확장되지만 병렬 컴퓨팅 리소스가 증가함에 따라 급격히 감소하고 있습니다. 2 차 최적화 방법은 잘 추정 된 그라디언트 및 대형 미니 배치에 대한 친화력을 가지므로 원칙적으로 병렬 계산에서 훨씬 많은 이점을 얻을 수 있습니다. 유감스럽게도 수백만 개의 매개 변수가있는 대형 모델로 확장하기 위해 곡률 행렬에 대한 엄격한 근사를 사용하여 모멘텀이있는 잘 조정 된 SGD 대 실용에서의 효율성을 제한합니다. 최근에 제안 된 K-FAC 방법 (Martens and Grosse, 2015)은보다 강하고 더 정교한 곡률 근사를 사용하며 SGD보다 더 많은 반복 당 진행을하는 것으로 나타났습니다. 이 논문에서는 K-FAC에서 요구하는 그라디언트 및 추가 계산을 여러 시스템에 분산시키는 K-FAC의 버전을 개발함으로써이 방법의 대형 미니 배치에 대한 뛰어난 확장 성을 활용하고 추가 오버 헤드. 우리는 사용하기 쉽고 변경하지 않고 많은 기존 코드베이스에 적용 할 수있는 접근 방식의 Tensorflow 구현을 제공합니다. 또한, 우리는 매우 큰 모델의 계산 성능을 향상시킬 수있는 K-FAC에 대한 몇 가지 알고리즘 개선 사항을 개발합니다. 마지막으로 분산 K-FAC 방법을 사용하면 일괄 정규화의 개선 된 형태 (Ioffe and Szegedy, 2015)와 비교하여 여러 최첨단 ImageNet 분류 모델의 학습 속도를 2 배 향상시킬 수 있음을 보여줍니다.

# 1 INTRODUCTION

현재의 최첨단 딥 뉴럴 네트워크 (Szegedy et al., 2014; Krizhevsky et al., 2012, He et al., 2015)는 수 백만 회의 교육 사례로 수 일간의 교육 시간을 필요로합니다. 신경망 훈련을 가속화하는 전형적인 전략은 많은 기계 및 클러스터 노드에 더 많은 병렬 자원을 할당하는 것입니다 (Dean et al., 2012). 병렬 교육을 통해 연구원은 다른 기계가 미니 배치의 여러 분할을 계산하는 큰 모델을 구축 할 수 있습니다. 수년에 걸쳐 분산 형 교육 설정을 향상 시켰지만 신경 네트워크는 여전히 다양한 SGD (first-order stochastic gradient descent) 알고리즘으로 교육을 받았습니다. SGD가 모델의 크기와 데이터 세트의 크기에 따라 얼마나 잘 확장되었지만 병렬 계산 리소스로는 확장되지 않습니다. 큰 일괄 처리 및 병렬 처리 계산이 늘어남에 따라 SGD 및 관련 알고리즘에 대한 수익이 감소합니다.
목적 함수의 곡률을 설명하는 업데이트를 구성하기 위해 2 차 정보를 사용하는 2 차 최적화 방법은 유망한 대안을 제시합니다. 정준 2 차 법은 큰 곡률 행렬 (전통적으로 헤 시안)을 반전시킴으로써 작동하지만 수백만 개의 매개 변수가있는 딥 뉴럴 네트워크에는 잘 맞지 않습니다. 곡률 행렬에 대한 다양한 근사는 대각선 (LeCun et al., 1998; Duchi et al., 2011; Kingma and Ba, 2014), 대각선 Le Roux et al. (Schraudolph et al., 2007; Bordes et al., 2009; Wang et al., 2014; Keskar and Berahas, 2015; Moritz et al., 2016; Byrd et al., 2016) Curtis, 2016, Ramamurthy와 Duffy). 또 다른 전략은 반전 문제를 완전히 피하기 위해 Krylov-subspace 방법과 효율적인 행렬 - 벡터 곱셈 알고리즘을 사용하는 것입니다 (Martens, 2010; Vinyals and Povey, 2012, Kiros, 2013, Cho et al., 2015; He et al., 2016 ).
곡률 근사법과 관련된 일반적인 문제, 특히 낮은 순위와 대각선 문제는 매우 원시적이며 객관적 기능에서 실제 곡률의 모형 외면을 나타낼뿐입니다. 반면 Krylov-subspace 방법은 여전히 ​​1 차 방법에 의존하여 업데이트를 계산하기 때문에 어려움을 겪습니다.
보다 최근에는 피셔 정보 매트릭스 (Heskes, 2000; Ollivier, 2013; Grosse and Salakhutdinov, 2015; Povey et al., 2015; Desjardins et al., 2015)의 통계적 근사에 근거하여 몇 가지 근사가 제안되었다. K-FAC 접근법 (Martens and Grosse, 2015, Grosse and Martens, 2016)에서 이러한 근사는 각 블록이 크로네 커 (Kronecker)로 근사되는 Fisher 정보 행렬 (전체 계층에 해당하는 블록 포함)에 블록 대각 근사화를 초래합니다 훨씬 더 작은 두 개의 행렬의 곱이며, 둘 다 상당히 효율적으로 추정되고 반전 될 수 있습니다. 두 행렬의 크로네 커 생성물의 역함수는 반전 된 크로네 커 생성물이므로 전체 행렬을 효율적으로 뒤집을 수 있습니다.
Martens and Grosse (2015)는 K-FAC이 중형에서 대형 크기의 미니 배치에 대해 미니 배치 크기와 반복 실행간에 거의 선형 관계를 유지하면서 SGD에 비해 더 큰 미니 배치에 매우 적합한 것으로 나타남을 발견했습니다. 이 현상에 대한 한 가지 가능한 설명은 2 차 방법이 오차 표면을 탐구하고 그라디언트 노이즈 (미니 배치 크기에 반비례 함)가 수렴에서 가장 중요한 제한 요소가되는 지역 최소값 근처에 도달하는 것이 더 신속하게 진행된다는 것입니다 1. 이 관찰은 K-FAC이 특히 고도로 병렬 분산 된 구현의 이점을 누릴 수 있음을 의미합니다.
본 논문에서는 많은 양의 병렬 컴퓨팅 자원을 효율적으로 활용할 수있는 K-FAC의 비동기식 분산 버전을 제안하고 수억 개의 매개 변수를 갖는 산업 규모의 신경망 모델로 확장합니다. 이 방법은 근사 피셔를 업데이트하고 그 역수를 계산하는 추가 계산 노드를 사용하여 기존의 분산 형 동기식 SGD 설정을 보완합니다. 제안 된 방법은 일반적인 4 GPU 클러스터에서 동일한 미니 배치 크기를 사용하는 일반 SGD와 유사한 반복 실행 시간을 달성합니다. 우리는 또한 입력이 일반적으로 표준 크로네 커 - 인수 근사에 의해 처리하기에는 너무 큰 특징 맵인 레이어에 대해 "이중으로 조작 된"크로네 커 근사를 제안합니다. 마지막으로, 제안 된 방법이 Batch Normalization (Ioffe and Szegedy, 2015)에 비해 다양한 최신 ImageNet 모델 학습 속도를 2 배로 향상 시킨다는 것을 경험적으로 입증합니다.

# 2 배경

## 2.1 KRONECKER FACTORED APPROXIMATE FISHER

DW를 신경 회로망의 대수 우도 L의 기울기 라하자. 어떤 가중치 행렬 W ∈ RCout × Cin을 층에 넣고, 여기서 Cin, Cout은 층의 입출력 단위의 수입니다. 그 층의 Fisher 정보 행렬의 블록은 다음과 같이 주어진다.

여기서 P는 입력 x에 대한 분포이고 목표 y에 대한 네트워크의 분포 (로그 가능성 목표에 의해 함축 됨)입니다. 이 논문 전체에서 우리는 달리 언급하지 않는 한, P에 대한 기대가 있다고 가정한다 (y에 대한 훈련 분포가 아니라).
K-FAC (Martens and Grosse, 2015, Grosse and Martens, 2016)는 Kronecker 인수 요인을 사용하며,
우리가 지금 묘사하고있는 각 블록에 이메이션. 입력 활성화 벡터를 다음과 같이 나타냅니다.
A ∈ RCin, s = WA와 같은 사전 활성화 입력 및
Ds = dL ∈ RCout. 가중치의 기울기는 입력 액의 외적입니다.
vation과 back-propagation 된 파생물 DW = DsA. K-FAC은 Fisher 블록을 입력의 2 차 통계 및 파생 된 파생 상품의 크로네 커 곱으로 근사합니다.

이 근사값은 활성화와 역 전파 파생 정보의 2 차 통계가 상관 관계가 없다는 가정을하는 것으로 해석 할 수 있습니다.
##2.2 K-FAC를 사용하는 대략 자연적 인 급료
자연스러운 그라디언트 (Amari, 1998)는 피셔의 역행렬과 그라디언트의 곱으로 정의됩니다. 전통적으로 KL- 발산을 사용하여 측정 한 네트워크의 출력 분포에서 단위 변경 당 목표에서 가장 큰 (즉각적인) 개선을 달성하는 매개 변수 공간의 방향으로 해석됩니다. 거의 항상 실제로 실행되는 특정 조건 하에서, 그것은 log-likelihood objective의 국부적 인 2 차 회귀를 최소화함으로써 계산 된 2 차 갱신으로 해석 될 수 있는데, 여기서 Hessian은 Fisher (Martens, 2014 ).
K-FAC의 대략적인 자연 그라디언트를 계산하기 위해 각 레이어의 가중치에 대한 그래디언트에 해당 레이어의 해당 Fisher 블록 F의 역수를 곱합니다. 의미
가중치 W에 대한 손실 함수의 GW ∈ RCin × Cout에 의한 기울기. 우리는
Martens and Grosse에 의해 설명 된 인수 분해 된 Tikhonov 댐핑 접근법의 사용을 가정하십시오
(2015) 여기서 댐핑 항 λI ~ F의 합은 πλ1 I에 A2를가함으로써 근사화된다
 ⊤ 1
E AA 및 πDsλ2 I 내지 E DsDs, 여기서 πA 및 πD는 설명 된 조정 인자이다
세부 사항은 Sec. 4.1. (λ를 가진 임의의 L2 정규화 용어로부터 곡률에 대한 기여도를 포함 할 수 있음을주의하십시오.)
근사 자연 그라디언트 업데이트 v는 다음과 같이 베이시픽 (AniB) -1 = (A-1≤B-1) 및 (A≤B) vec (C) = vec (BCA⊤)
   -1 ⊤ 1 -1 ⊤ 1 -1 v = F + λI vec {GW} ≈ vec E AA + πAλ2 I GW E DsDs + πDsλ2 I
(3) 대략적으로 행렬을 포함하는 곱셈 연산의 여러 행렬 반전에 해당
가중치 행렬 W와 동일한 크기.
#3 K-FAC를 이용한 분산 최적화
확률 적 최적화 알고리즘은 저 분산 그라디언트 추정의 이점을 제공합니다 (큰 미니 배치에서 얻을 수 있음). 이전 연구는 대략적인 자연 경사 알고리즘이 표준 SGD보다 분산을 줄이는 데 더 도움이 될 수 있다고 제안했습니다 (Martens and Grosse, 2015; Grosse and Martens, 2016). 저 분산 그라디언트 추정을 효율적으로 얻는 한 가지 방법은 분산 시스템의 여러 시스템에서 그라디언트 계산을 병행하는 것입니다 (따라서 대형 미니 배치를 효율적으로 처리 할 수 ​​있습니다). K-FAC의 그래디언트 계산은 SGD의 그래디언트 계산과 동일하기 때문에 표준 동기 SGD 모델을 사용하여 그래디언트 계산을 병렬 처리합니다.
그러나 K-FAC은 SGD에서 볼 수없는 다른 형태의 오버 헤드, 특히 2 차 통계량의 추정과 크로 네커 요인의 역원 또는 고유치 계산을 소개합니다. 이 섹션에서는 이러한 추가 계산을 비동기 적으로 수행하는 방법에 대해 설명합니다. 이 비동기식 계산은 알고리즘에 추가 오류 소스를 가져 오지만 실제로는 반복 당 진행률에 큰 영향을 미치지 않습니다. 결론적으로 분산 K-FAC 구현의 반복 월 클럭 시간은 동일한 미니 배치 크기의 동기 SGD에 비해 5-10 % 정도 높습니다.
##3.1 비 수직 피셔 차단기 유입
식 3에 따라 매개 변수 갱신을 계산하려면 추정 된 기울기에 작은 크로네 커 계수의 역수를 곱해야합니다. 이를 위해서는 주기적으로 (일반적으로) 이러한 요인 각각의 역변환이나 고유 분해를 계산해야합니다. 이러한 요인은 일반적으로 크기가 수백 또는 수천만에 불과하지만 매우 깊은 네트워크의 경우 수백 개의 매트릭스가있을 수 있습니다 (각 레이어에 2 개 이상). 또한, 행렬 역전 및 고유 분해는 GPU 계산의 이점을 거의 볼 수 없기 때문에 표준 신경망 작업보다 비싸다. 이러한 이유로, 대략적인 피셔 블록을 반전시키는 것은 상당한 계산 비용을 나타냅니다.
피셔 블록의 역순을 가끔씩 새로 고치고 오래된 값을 사용하면 곡률이 비교적 천천히 변하기 때문에 평균 반복 당 진행에 작은 해로운 영향을 미친다는 것이 관찰되었습니다 (Martens and Grosse, 2015). 우리는 네트워크가 여전히 교육을받는 동안 반전을 비동기식으로 계산함으로써 이것을 더욱 발전시킵니다. 필요로하는 선형 대수 연산은 CPU- 바운드이고 나머지 계산은 GPU- 바운드이기 때문에, 우리는 거의 효과적인 오버 헤드없이 CPU에서 수행합니다. 결과적으로 곡률 통계는 다소 오래 동안 지속되었지만 반복성 최적화 성능에 큰 영향을 미치지는 않습니다. 우리의 실험에서 우리는 반전을 비동기 적으로 계산하는 것이 K-FAC 알고리즘의 전반적인 벽 시계 시간에 대해 40-50 %의 속도 향상을 제공한다는 것을 발견했습니다.
##3.2 비 정적 통계 계산
K-FAC에서 계산 오버 헤드의 다른 주요 소스는 크로네 커 요인에 필요한 활성화 및 파생 상품의 2 차 통계량을 추정하는 것입니다. 표준 K-FAC 알고리즘에서 이러한 통계는 그라디언트와 동일한 미니 배치에서 계산되므로 포워드 패스 계산을 그라디언트와 통계 계산간에 공유 할 수 있습니다. 별도의 미니 배치에 대한 그래디언트와 통계를 계산하여 더 높은 수준의 병렬 처리를 가능하게 할 수 있습니다. 약간 더 많은 계산 작업이 필요합니다. 이 기법에서 통계 추정은 그래디언트 계산과는 독립적이므로 독립적 인 데이터 샤드를 사용하여 하나 이상의 개별 작업자 노드에서 수행 할 수 있습니다. 이러한 작업자 노드는 (동기 SGD에서와 마찬가지로) 매개 변수 서버에서 매개 변수를 수신하고 통계를 매개 변수 서버로 다시 전달합니다. 우리의 실험에서 우리는 계산 통계에 최대 한 명의 작업자를 할당했습니다.
별도의 작업자 노드를 컴퓨팅 통계에 사용하는 것이 바람직하지 않은 경우에는 컨볼 루션 계층에 대한 통계에 대한 빠른 근사도 소개합니다 (부록 A 참조).

#4. 대용량 단층 촬영을위한 DOUBLY-FACTORED KRONECKER의 예측
주어진 층에 대한 표준 크로네 커의 Fisher 근사를 계산하는 것은 차원이 입력 단위 또는 출력 단위의 수인 행렬에 대한 연산을 포함합니다. 이러한 작업의 비용은 각 계층의 장치 수가 거의 몇 천 개를 초과하지 않기 때문에 대부분의 완전 연결된 네트워크에 적합합니다. 그러나 대형 콘볼 루션 신경망은 종종 최종 Softmax 분류 전에 큰 기능 맵에 "풀링"하는 완전 연결 계층을 포함합니다. 예를 들어, AlexNet의 마지막 풀링 레이어의 출력은 6 × 6 × 256 = 9216 크기이며, 이후 4096 ReLUs의 완전히 연결된 연속 레이어에 입력을 제공합니다. VGG 모델도 비슷한 아키텍처를 공유합니다. 표준 크로네 커 요인 근사화의 경우 요인 중 하나는 크기가 9216 × 9216 인 행렬이 될 것이고 이는 교육 과정에서 필요에 따라 명시 적으로 뒤집을 수 없을만큼 비싸다.
이 섹션에서는 입력이 큰 피쳐 맵인 레이어에 대해 "이중 인수"크로 네커 근사를 제안합니다. 특히 입력의 2 차 통계 행렬을 크로네 커 (Kronecker) 제품으로 분해하여 근사합니다. 이것은 3 개의 행렬의 크로네 커 (Kronecker) 산물 인 근사값을 제공합니다.
AlexNet 예제를 사용하면 첫 번째 완전히 연결된 레이어의 9216 × 4096 가중치 행렬은 256 입력 채널에서 커널 크기가 6 × 6 인 4096 필터의 필터 뱅크와 같습니다. A를 (T = Kw × Kh은 피쳐 맵의 높이와 너비이고, Cin은 입력 채널의 수) 인 입력 활성화를 나타내는 차원 T-by-Cin의 행렬이라고하자. 이러한 레이어의 피셔 블록은 다음과 같이 작성할 수 있습니다.
E [vec {DW} vec {DW} ⊤] = E [vec {A} vec {A} ⊤ ⊗ DsDs⊤], A ∈ RT × Cin. (4) 우리는 다음 순위 1 근사값을 만들기 시작합니다.
A ≈ KΨ⊤,
(5)
여기서 K∈RT, Ψ∈RCin은 실제 배치 차원과 입력 채널 차원에 걸친 요인들입니다. Frobenius norm 하에서의 낮은 랭크 근사의 최적 해는 특이 값 분해에 의해 주어진다. 활성화 행렬 A는 SVD가 효율적으로 계산 될 수있을만큼 충분히 작습니다. σ1, u1, v1을 각각 활성화 행렬 A의 첫 번째 특이 값과 왼쪽 및 오른쪽 특이 벡터라고하자. 랭크 -1 근사화의 요인은 K = √σ1u1 및 Ψ = √σ1v1로 선택된다. K는 기능 맵에서 공간 위치 전체의 활성화 패턴을 캡처하고 Ψ는 필터 응답에서 패턴을 캡처합니다. A의 랭크 -1 근사치에서 우리는 다음을 얻습니다.
E [vec {A} vec {A} ⊤ D DsDs⊤] ≈ E [vec {KΨ⊤} vec {KΨ⊤} ⊤ ⊗ DsDs⊤] (6) = E [KK⊤ ⊗ ΨΨ⊤ ⊗ DsDs⊤]. (7)
우리는 또한 2 차 통계가 손실 파생물 Ds, 입력 채널 Ψ에 따른 활성화 및 공간 위치 K를 따른 활성화 사이에서 3 방향 독립이라고 가정합니다.
E [vec {DW} vec {DW} ⊤] ≈ E [KK⊤] ⊗ E [ΨΨ⊤] ⊗ E [DsDs⊤]. (8)
최종 근사 피셔 블록은 세 개의 작은 행렬의 크로네 커 (Kronecker) 산물입니다. 그리고 우리가 feature map activation이 낮은 등급 구조를 가졌다 고 가정 하였지만, 결과로 나온 대략적인 피셔는 낮은 등급이 아니다.
이 계층에 대한 대략적인 자연 그라디언트는 각 그라디언트의 역수를 그라디언트 텐서의 각 차원에 곱하여 계산할 수 있습니다. 원하는 목표 차원 i ∈ {1, 2, 3}이 열에 매핑되도록 3D 텐서에서 행렬을 구성하는 함수 Ri : Rd1 × d2 × d3 → Rdj dk × di를 정의합니다. 나머지 치수 (j 및 k)는 "함께 접혀"행에 매핑됩니다. 가중치의 기울기 GW ∈ RT × Cin × Cout이 주어지면 행렬 - 벡터 곱을 역 이중 인자 Kronecker 근사 피셔 블록으로 계산할 수 있습니다.
-1 ⊤ -1 -1 ⊤ -1 -1 ⊤ -1
R3 E [DsDs] R3 R2 E [ΨΨ] R2 (R1 (E [KK] R1 (GW))). (9)

이는 그라데이션 텐서의 각 차원에서 변형 함수 R (·)의 중첩 된 적용입니다.
이중으로 분해 된 크로네 커 근사법은 수천만 개의 매개 변수를 갖는 레이어의 표준 크로네 커 - 팩터링 근사에 대한 계산 가능한 실현 가능한 대안을 제공합니다. 예를 들어, AlexNet의 첫 번째 완전히 연결된 레이어에 대한 반전은 8 코어 Intel Xeon CPU에서 약 15 초가 걸리고 이러한 시간은 비동기식 알고리즘으로 상각됩니다.
불행하게도, 동질적인 좌표 공식은이 새로운 접근법에서 더 이상 적용 할 수 없다. 대신, 우리는 바이어스 매개 변수를 함께 모으고 전체 피셔 블록을 그들과 관련시킵니다. 이것은 레이어 당 바이어스 매개 변수 수가 적기 때문에 명시 적으로 계산되고 반전 될 수 있습니다.
## 4.1 이중 결합 된 클론 테이커의 근사를위한 TIKHONOV DAMPING의 FACTORED
2 차 최적화 방법에서 "댐핑"은 업데이트를 계산할 때 (아마도 암시 적으로) 최적화 된 목표의 로컬 2 차 근사의 부정확성을 수정하는 중요한 작업을 수행합니다 (Martens and Sutskever, 2012, Martens, 2014 , 예). 잘 알려진 Tikhonov 댐핑 / 정규화 접근법에서 피셔 (Fisher)에 정체성 λI의 배수를 더한다 (L2 정규화 / 체감 감량과 마찬가지로). 구형 신뢰 영역을 부과하는 것과 대략 일치한다 업데이트.
크로네 커 생성물의 역행렬은 그 요인들의 역의 크로네 커 생성물로서 효율적으로 계산 될 수 있습니다. 아이디의 배수를 추가하면이 계산이 복잡해집니다 (단, 고유 분해를 사용하여 현저하게 수행 할 수 있음). (Martens and Grosse, 2015)에서 제안 된 "Tchhonov 댐핑 (Factorized Damping)"기법은 크로네 커 구조의 분해를 보존하기 때문에 매력적입니다. 따라서 더 작은 각 행렬을 반전시킴으로써 역변환을 계산할 수있다. (더 비싼 고유 분해 연산 ). 그리고 대형 ImageNet 모델을 사용한 실험에서 실제로 감쇠가 더 잘 수행되는 것으로 관찰됩니다. 이 절에서 우리는 double-factored 크로네 커 근사를위한 Tikhonov 댐핑의 일반화 된 버전을 유도합니다.
우리가 근사 피셔 블록 Aλ B를 추가하고자한다고 가정하자. 계수 화 된 Tikhonov 111
πa πb πc = 1을 만족하는 음이 아닌 스칼라 πa, πb 및 πc에 대해 πaλ3 I, πbλ3 I 및 πcλ3 I을 각각 A, B 및 C에 더함으로써 근사화됩니다.이 근사와 관련된 오류는 다음과 같습니다.
   111
(A + πaλ3 I) ⊗ (C + πcλ3 I) - (A ⊗ B ⊗ C + λI) (10)
111
= πcλ3 I ⊗ A ⊗ B + πbλ3 I ⊗ A ⊗ C + πaλ3 I ⊗ B ⊗ C
i11111
+ πcλ3 I ⊗ πbλ3 I ⊗ A + πcλ3 I ⊗ πaλ3 I ⊗ B + πaλ3 I ⊗ πbλ3 I ⊗ C (11)
Martens and Grosse (2015)에 따르면, 우리는 식 (5)의 핵 표준을 취함으로써 πa, πb 및 πc를 선택합니다. 11을 계산하고 삼각형 부등식에서 유도 된 상한값을 최소화합니다. 크로네 커 제품의 핵 규범은 각 행렬의 핵 규범의 산물이다 : ∥A ⊗ B∥ * = ∥A∥ * ∥B∥ *. 이것은 πa 값에 대해 다음 공식을 제공합니다.
 3 ∥A∥ * 2 ∥B∥ * ∥C∥ * -1
πa = dd d. (12)
알파벳
여기서 d' s는 해당 크로네 커 계수 행렬의 행 수 (등가 열)입니다. πb와 πc에 해당하는 공식은 유사합니다. 직관적으로, Eq. 12는 다른 요인 행렬의 표준과 표준의 비율의 기하 평균에 따라 각 요인 행렬에 대한 기여도를 다시 측정합니다. 예를 들어, 요인의 표준이 평균 표준보다 클 경우에는 기여도가 높아집니다. 이 공식은 Kronecker의 임의의 수의 행렬 곱을 표준 비율의 기하 평균으로 일반화합니다.

#5. 단계 크기 선택
Grosse and Martens (2016)는 Polyak 평균 (Polyak and Juditsky, 1992)이 일부 문제에 대한 학습률 스케쥴 조정의 필요성을 발견 했음에도 불구하고 우리는 ImageNet 실험에서 학습률 스케쥴의 선택이 중요한 요소임을 관찰했다. 아마도 업데이트의 확률이 높아짐에 따라). ImageNet에서 고정 된 지수 감쇠 스케줄 (Szegedy et al., 2014; 2015)을 사용하는 것이 일반적입니다. 속도 스케줄을 학습하는 대신, 각 업데이트 후에 예측 분포가 변경되는 양을 제어하기 위해 곡률 정보를 사용합니다. 특히, 파라미터 업데이트 벡터 v가 주어지면, 업데이트 전후의 예측 분포 사이의 KL 발산에 대한 2 차 테일러 근사값은 (제곱 된) 피셔 표준에 의해 주어진다 :
DKL [q || p] ≈ 1v⊤Fv (13) 2
이 양은 곡률 벡터 곱으로 계산할 수 있습니다 (Schraudolph, 2002). 스텝 사이즈 η를 선택하면 Fisher norm η2 v⊤Fv의 제곱으로 업데이트가 생성됩니다. 학습 속도 스케쥴을 사용하는 대신, 우리는 각 반복에서 η를 선택하여 피셔 표준의 제곱이 최대 값 인 c :
   기음
η = min ηmax, v⊤Fv (14)
Grosse and Martens (2016)는이 방법을 사용하여 교육 시작시 업데이트를 정리했지만 교육 과정에서이 방법을 사용하는 것이 유용하다는 것을 알았습니다. 지수 감쇠 스케쥴 ck = c0ζk를 사용합니다. 여기서 c0와 ζ는 조정 가능한 매개 변수이고, k는 주기적으로 증가합니다 (우리의 ImageNet 실험에서 반세기마다). 매 갱신 후 모델 예측에서 최대 변화를 줄이는 것은 2 차 최적화의 신뢰 영역을 축소하는 것과 유사하다. 실제로 모든 업데이트 후에 곡률 벡터 곱을 계산할 때 상당한 계산 오버 헤드가 발생하므로 F 대신 Fisher F를 사용하여 Fisher norm을 근사 피셔 norm을 v  F v = v ⊤ F (F- 1GW) = v⊤GW입니다. 최대 스텝 크기 ηmax는 큰 값으로 설정되었고, 실제로이 최대 값은 F의 크기가 작은 훈련 시작 부분에만 도달했습니다. 우리는 ImageNet 실험에서이 우수한 지수 함수 학습 률을 능가하는 것으로 나타났습니다 (부록 B 참조).

#6 실험
우리는 실험적으로 CIFAR-10 및 ImageNet 분류 데이터 세트를 포함하는 여러 개의 큰 길쌈 신경 네트워크 훈련 작업에 대해 분산 K-FAC를 평가했습니다.

전산 자원의 제약으로 인해 대형 분산 시스템을 시뮬레이션하기 위해 8 개의 Nvidia K80 GPU가있는 단일 GPU 서버를 사용했습니다. GPU는 그라디언트 작업자로 사용되어 CPU가 매개 변수 서버 역할을하는 대형 미니 배치를 통해 그라데이션을 계산했습니다. 피셔 블록 반전은 가능한 한 많은 스레드를 사용하여 CPU에서 병렬로 수행되었습니다. 다양한 피셔 블록 근사에 필요한 2 차 통계는 각 그래디언트 계산 (CIFAR-10 실험) 후 그라디언트 작업자가 동시에 계산하거나 별도의 전용 "통계 작업자"(ImageNet 실험)를 비동기 적으로 계산했습니다.

학습 속도, 감쇠 매개 변수 및 2 차 통계의 감쇠율과 같은 메타 파라미터는 각 방법에 대해 수작업으로 조심스럽게 최적화되었습니다. 운동량은 0.9로 고정되었다.

Martens and Grosse (2015)와 마찬가지로, 우리는 지수 적으로 감쇠 된 Polyak 평균화 기법을 각 방법에 의해 생성 된 출력 반복 시퀀스에 적용했습니다. 우리는 이것이 최적화의 후반 단계에서 그들의 수렴 속도를 향상시키고 학습 률을 감소시킬 필요성을 줄이거 나 없애 주었다.

우리는 TensorFlow 프레임 워크 (Abadi et al., 2016)에서 분산 K-FAC 구현을 기반으로하기 때문에 분산 계산을위한 잘 설계되고 확장 가능한 프리미티브를 제공합니다. 그라디언트 계산에 특정 구조가있는 매개 변수 그룹에 대해 그라디언트 계산 그래프를 스캔하여 TensorFlow에 분산 된 K-FAC을 구현합니다. 이러한 그룹을 확인하면 관찰 된 구조 유형에 맞는 방법을 사용하여 피셔 블록을 계산 / 근사합니다. 자세한 내용은 부록 C를 참조하십시오. 이러한 유형의 구현은 상기 코드를 크게 수정하지 않고 기존의 모델 - 스펙 코드에 적용될 수있다. TensorFlow의 병렬 프리미티브는 확장 성을 염두에두고 설계 되었기 때문에 구현을 수백 명의 직원이있는 더 큰 분산 시스템으로 확장 할 수 있어야합니다.

관찰되었다. 자세한 내용은 부록 C를 참조하십시오. 이러한 유형의 구현은 상기 코드를 크게 수정하지 않고 기존의 모델 - 스펙 코드에 적용될 수있다. TensorFlow의 병렬 프리미티브는 확장 성을 염두에두고 설계 되었기 때문에 구현을 수백 명의 직원이있는 더 큰 분산 시스템으로 확장 할 수 있어야합니다.

##6.1 CIFAR-10 분류 및 비 수직 피셔 블록 유입
첫 번째 실험에서 3.1 절에서 설명한 피셔 반전을 비동기 적으로 계산하는 효과를 평가했습니다. 우리는 이것이 목표에 대한 반복 당 진행에 의해 측정 된 업데이트의 품질과 반복적 인 평균 월간 시간에 영향을 미친다 고 생각했습니다.
이 작업은 CIFAR-10 이미지 분류 데이터 세트 (Krizhevsky and Hinton, 2009)에서 기본 컨볼 루션 네트워크 모델을 학습하는 것입니다. 이 모델에는 32 x 32-64 필터의 3 개의 컨볼 루션 레이어가 있으며 각 필드에는 수용 필드 크기가 5x5이고 그 다음에는 10 개의 클래스를 예측하는 softmax 레이어가 있습니다. 이것은 Grosse and Martens (2016)가 사용한 CIFAR-10 모델과 비슷하지만 동일하지는 않습니다. 모든 CIFAR-10 실험은 미니 배치 크기 512를 사용합니다.
기본 방법은 고정 된 학습률을 가진 분산 된 K-FAC의 간단한 동기식 버전이며 그라디언트 및 통계 작업자로 작동하는 최대 4 개의 GPU로 20 회 반복 할 때마다 대략적인 피셔 블록의 역산을 재 계산합니다. 이 기준 방법은 Grosse and Martens (2016)의 K-FAC 구현과 유사하게 작동하지만 병렬 처리 사용이 빨라 잠재적으로 더 빠릅니다. 이 기준선을 근사 피셔 블록이 비동기식으로 반전되고 나머지 최적화 프로세스와 병렬로 분산 된 분산 형 K-FAC 버전과 비교합니다. 이 스킴에서 역수는 단일 GPU 조건에 대해 16 회 반복하고 4 회의 GPU 조건에 대해 매 30 회 반복 업데이트됩니다. 비교적 작은 CIFAR-10 네트워크보다 큰 네트워크의 경우 업데이트 속도가 훨씬 느려질 수 있습니다 (예 : 6.2.2 절의 AlexNet 실험).
이 첫 번째 실험의 결과는 그림 2에 그려져 있습니다. 비동기 버전은 동기식 버전보다 약 1.5 배 더 빠른 속도로 반복되는 반면, 반복 당 진행률은 비슷합니다. 플롯은 비동기 버전이 병렬 계산을 활용할 때 더 우수하며 그라디언트 작업자 수가 4 명으로 증가함에 따라 거의 선형 속도 향상을 보였음을 보여줍니다. 벽 시계 시간 측면에서 4 GPU 만 사용하면 분산 K-FAC은 최소 테스트 오류 (19 %)를 달성 한 후 분당 700 회 반복을 완료 할 수 있습니다.

##6.2 이메이션 분류
우리의 두 번째 실험 세트에서 우리는 분산 된 K-FAC을 여러 다른 인기있는 접근법에 대해 벤치마킹하고 반복 실행 당 진행에 미니 배치 크기의 영향을 고려했습니다. 이를 위해 우리는 ImageNet 데이터 세트의 이미지 분류를 위해 다양한 기성의 convnet 아키텍처를 교육했습니다
(Russakovsky et al., 2015) : AlexNet (Krizhevsky 외, 2012), GoogLeNet InceptionV1 (Szegedy 외 2014) 및 50 층 잔여 네트워크 (He et al., 2015).
ImageNet 교육 세트에 120 만 개의 이미지가 있음에도 불구하고 이미지 사전 처리 파이프 라인은 이미지 지터 및 측면 왜곡이 포함 된 ImageNet 교육에 거의 항상 사용됩니다. 이 백서의 목적은 최첨단 ImageNet 결과를 달성하는 것이 아니라 분산 데이터베이스의 최적화 성능을 평가하기 위해 일반적으로 이미 사용되는 것보다 덜 광범위한 데이터 세트 확대 / 전처리 파이프 라인을 사용했습니다 K-FAC. 특히, 데이터 세트는 224x224 이미지로 구성되며 학습 도중 원본 이미지는 먼저 256x256 크기로 조정 된 다음 네트워크에 공급되기 전에 무작위로 다시 224x224로 자릅니다. 일반적으로 유효성 검증 오류가 학습 오류보다 높지만 ImageNet 용 데이터 사전 처리 파이프 라인은 왜곡되지 않은 유효성 검증 세트보다 어려운 추가 증가 세트를 작성하므로 유효성 검증 오류가 종종 교육보다 낮습니다 교육의 처음 90 % 동안 오류가 발생했습니다. 이 관찰은 이전에 발표 된 결과와 일치한다 (He et al., 2015).
모든 ImageNet 실험에서 부록 A의보다 저렴한 Kronecker 인수 분해 및 5 절에서 설명 된 KL 기반 단계 크기 선택 방법을 매개 변수 c0 = 0.01 및 ζ = 0.96으로 사용했습니다. SGD 기준선은 0.96의 감쇠율을 갖는 지수 학습 율 감쇠 계획을 사용합니다. 분산 된 K-FAC 및 SGD + 일괄 정규화를위한 각 반 에포크 이후, 그리고 Ioffe 및 Szegedy (2015)의 실험 설정과 일치하는 일반 SGD에 대해 매 2 개의 신기원마다 붕괴가 적용됩니다.

###6.2.1 오마이 뉴스 및 일괄 NORMALIZATION
Batch Normalization (Ioffe and Szegedy, 2015)은 신경망을 다시 매개 변수화하여 1 차 방법으로 쉽게 학습 할 수있게 해주 며 대규모 Imaging 네트워크 모델에도 성공적으로 적용되었습니다. 이것은 신경 네트워크의 단위를 변형 한 것으로 생각할 수 있으므로 각 미니 배치는 현재 미니 배치 (또는 하위 집합)에 대해 자체 원시 입력을 센터링하고 표준화 한 다음 해당 미니 배치를 사용하여 별도의 시프트 및 스케일링 연산을 적용합니다. 로컬 "바이어스"및 "게인"매개 변수 (최적화되어 있음). 이러한 이동 및 크기 조정 작업은 센터링 및 정규화를 효과적으로 취소하여 네트워크가 계산할 수있는 기능 클래스를 유지하는 방법을 배울 수 있습니다. BN (Batch Normalization)은 센터링 기술과 밀접한 관련이 있으며 (Schraudolph, 1998) 대체 매개 변수화가 유리한 곡률 특성을 갖는 손실 표면을 발생시키는 것과 동일한 이유에서 도움이 될 가능성이 높습니다. BN과 전통적인 센터링의 주된 차이점은 BN이 센터링 및 정규화 작업을 최적화 알고리즘 대신 모델의 일부로 만든다는 것입니다. 따라서 그라디언트를 계산할 때 BN이이를 통해 "백 프로덕트"를 수행하므로 최적화가 안정됩니다.
알고리즘을 변경하지 않고 분산 된 K-FAC을 사용하여 BN 레이어가있는 신경망을 학습 할 수 있습니다. 이러한 레이어의 가중치 행렬 그래디언트는 표준 레이어와 동일한 구조를 가지므로 피셔 블록은 동일한 기술 집합을 사용하여 근사 할 수 있습니다. 단위당 이득 및 바이어스 매개 변수는 사소한 문제를 일으키지 만 상대적으로 적기 때문에 각 피셔 블록을 계산할 수 있습니다.
대형 미니 배치를 통한 BN 네트워크의 업데이트는 일반적으로 미니 배치를 크기 32의 덩어리로 분할하고 이러한 덩어리에 대해 개별적으로 그래디언트를 계산하여 (청크의 데이터 만 사용하여 평균 및 분산 통계를 계산 함), 그들을 함께 모으고. 이와 같이 통계를 계산하기 위해 작은 샘플 세트를 사용하면 정규화 자 역할을하는 BN 업데이트에 추가 확률이 도입되지만 최적화 성능을 저하시킬 수도 있습니다. 정규화 및 최적화의 효과를 분리하기 위해 큰 덩어리를 사용하는 BN 기준선과 비교했습니다. 큰 덩어리를 사용하면 표준 BN 기준선보다 최적화 성능이 2 배 향상됩니다. 우리의 그림에서 rbz는 청크 크기를 나타내며, 기본값으로 지정되지 않은 경우 32입니다.
그림 3에서는 BN이있는 경우와없는 경우 GoogLeNet에서 배포 된 K-FAC과 SGD를 비교합니다. 모든 방법은 전용 비동기 통계 작업자로 4 번째 GPU를 사용하는 분산 K-FAC를 사용하여 4 개의 GPU를 사용했습니다.

##6.2.2 ALEXNET 및 DOUBLY-FACTORED KRONECKER APPROXIMATION
분산 K-FAC이 매우 넓은 계층의 모델을 효율적으로 최적화 할 수 있음을 입증하기 위해 분산 K-FAC를 사용하여 AlexNet을 교육하고 SGD + BN과 비교합니다. 4 절에서 제안 된 이중 인자 Kronecker 근사는 9216 입력 단위를 갖는 AlexNet의 첫 번째 완전 연결 계층에 적용되므로 표준 크로네 커 근사가 실현 가능하기에는 너무 넓습니다. 이 추가 추정으로도 AlexNet에 대한 피셔 블록 역 전부를 계산하는 것은 매우 비쌉니다. 우리의 실험에서는 16 코어 Xeon 2.2Ghz CPU로 몇 백회 반복 할 때마다 업데이트됩니다.
이 실험의 결과는 그림 4에 그려져 있으며, 피셔 블록 반전의 극단적 인 stalleness에도 불구하고 Distributed K-FAC가 여전히 잘 작동 함을 보여줌으로써 향상된 SGD-BN 기준에 비해 1.5 배의 속도로 교육을 가속화합니다.

##6.2.3 심오한 건축술 (RESNETS)
최근 몇 년 동안 매우 깊은 컨벌루션 아키텍처가 ImageNet 분류에 성공적으로 적용되었습니다. 이러한 네트워크는 특히 심화 학습과 관련된 일반적인 어려움이 특히 심하기 때문에 훈련하기가 어렵습니다. 다행스럽게도 2 차 최적화는 강력하고 원칙적인 방법으로 이러한 어려움을 해결하는 데 이상적입니다 (Martens, 2010).
분산 된 K-FAC이 그러한 아키텍처에 확장 가능하고 유용한 가속화를 제공하는지 여부를 조사하기 위해 50 계층 ResNet 아키텍처 (He et al., 2015)를 사용하여 SGD + BN과 비교했습니다. 이 실험의 결과는 그림 5에 그려져 있으며, 분산 K-FAC은 SGD + BN과 비교하여 훈련 초기 단계에서 상당한 속도 향상을 제공함을 보여줍니다.
6.2.4 미니 배치 크기 확장 특성
마지막 실험에서 추가 병렬 컴퓨팅 리소스를 사용할 수있을 때 얼마나 잘 분산 된 K-FAC가 확장되는지 살펴 보았습니다. 이를 위해 {256, 1024, 2048}의 다양한 미니 배치 크기 및 교육 사례 별 진행 상황을 측정하여 GoogLeNet을 교육했습니다. 이상적인 경우, 여분의 그래디언트 데이터를 효율적으로 사용하는 경우, 미니 일괄 처리 크기와 관련하여 훈련 당 사례의 진행률이 상대적으로 일정하게 유지되어야합니다. 이 실험의 결과는 그림 6에 그려져 있으며 분산 된 K-FAC은 이러한 이상적인 동작에 가까운 것을 나타내지 만 SGD + BN은 256의 미니 배치 크기 이상으로 이동할 때 데이터 효율성을 빠르게 잃습니다. 이러한 결과는 분산 K-FAC은 SGD + BN 기준선보다 더 많이 사용되는 병렬 계산 리소스의 양에 비례하여 교육 속도를 높일 수 있습니다.

#7 토론
우리는 비동기식 분산 2 차 최적화 알고리즘 인 분산 형 K-FAC을 도입했습니다.이 알고리즘은 크론 캐커 인수 Fisher 근사 및 큰 미니 배치에 대한 비례 적 경사를 비동기식으로 병렬로 계산합니다.
우리의 실험에 따르면 분산 K-FAC에서 도입 된 여분의 오버 헤드는 병렬 비동기 계산을 사용하여 대부분 완화되므로 분산 SGD와 비슷한 시간에 업데이트를 계산할 수 있습니다. 반복마다 객관적인 기능. 실제로이 방법을 사용하면 표준 SGD + 일괄 정규화 (BN)에 비해 약 3.5 배의 속도 향상을 얻을 수 있으며 대규모 컨볼 루션 네트워크 교육 작업에서 BN의 향상된 버전 인 SGD +에 비해 2 배의 속도 향상을 보였습니다.
우리는 분산 형 K-FAC가 수억 개의 매개 변수를 가진 대형 모델까지 확장 할 수있게 해주는 이중 인자 Kronecker 근사법을 제안하고 실험에서이 접근법의 효율성을 입증했습니다.
마지막으로 우리는 분산 K-FAC이 SGD + BN과 공유되지 않는 미니 배치 크기로 유리한 확장 성을 누리고 있음을 보여주었습니다. 특히 반복 당 진행은 SGD + BN보다 훨씬 더 큰 임계 값까지 최소 배치 크기에 비례하는 경향이 있음을 보여주었습니다. 이것은 우리가 고려한 것보다 큰 분산 시스템에서 구현 될 때 벽시계 훈련 시간을 훨씬 더 단축 할 수 있음을 시사합니다.